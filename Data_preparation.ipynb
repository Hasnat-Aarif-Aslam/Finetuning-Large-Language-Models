{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-NxmfuOT5yB"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "height": 98,
        "id": "qSEqgeA468du"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import datasets\n",
        "\n",
        "from pprint import pprint\n",
        "from transformers import AutoTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "rvUVincE7-qD"
      },
      "source": [
        "### Tokenizing text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217,
          "referenced_widgets": [
            "a0b826e118e64a6faaa5755e955c5228",
            "bfc392837a6f4a909cc0aab2d49428a9",
            "d5327729d0e04cf6b9294d3902af1a20",
            "9a406322ffdd4079945b36b51b45fba0",
            "ccdf34a1a83e4849a9396bb9d196d5c7",
            "e5f1c6cc5b924a8385ce576e1f8be4fa",
            "686ef2eabd2a4e918b5b7efdb2fe594f",
            "11fa8772650f45e6b74e16ecdbcf2354",
            "aa97aea26c054a1d905ec627788431ba",
            "125ba063173c4dfa8e0c59395295e9f6",
            "ec827dfd90ad410f9e402f5c39c59740",
            "fdb0b76be8ee4571b67b84137d7f07ad",
            "771c33d24f3a49ca9dae0f8bc6feb76d",
            "9548741a9324407295737a635b3a277b",
            "8756ff5eb613473c9618fcdc9832dbeb",
            "c528fea2a20a438dbeb5f955efdf7895",
            "7ceb8655e9d1473da077aaa32152c7f3",
            "0605ca83d11a4a7a98af5332e5e6294e",
            "69c860edb9ef464e9a8b916b282c5613",
            "e2d1998314cf4f5697c927bb9fe33edd",
            "80eb453ec6764329bfcbc37a923ddb61",
            "bfaa21545f8f46ae8f659d7babfe8b67",
            "c5858226628340e8b91bc35bd633808a",
            "678e359174af4b83bdd7a22f7be02766",
            "3dc5cf08e0804504bd8f99de119681f8",
            "312f159065a645cd8d09cd2a30f44b22",
            "5de7d69da1694389a6e5c57fb34d8fa5",
            "08dcaab7783c43e8bcb104bd873e43d1",
            "c70fd05649a44354ae43080afcc38d2e",
            "ab1b4b70f3c84513a067971ba6359989",
            "82ecae102ed94347ab36ee60ccca61e5",
            "ed4c66c7edad42cfb519c09c30ac9ae3",
            "270d6e47ea9845b28246cfc93fda8e47"
          ]
        },
        "id": "i6BYxUgR7-qD",
        "outputId": "38e7bce1-8b41-4231-ca3b-e2adea674efc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/396 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a0b826e118e64a6faaa5755e955c5228"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fdb0b76be8ee4571b67b84137d7f07ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5858226628340e8b91bc35bd633808a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/pythia-70m\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "height": 30,
        "id": "HR2ye1la7-qD"
      },
      "outputs": [],
      "source": [
        "text = \"Hi, how are you?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "height": 30,
        "id": "etksh88A7-qD"
      },
      "outputs": [],
      "source": [
        "encoded_text = tokenizer(text)[\"input_ids\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "height": 30,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEXSB61z7-qD",
        "outputId": "7e24ae4b-48a5-43ac-a69a-69cc2a495471"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[12764, 13, 849, 403, 368, 32]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "encoded_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "height": 47,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlU2vxwJ7-qD",
        "outputId": "8492f5f0-628c-475c-9d41-0da53596aacf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded tokens back into text:  Hi, how are you?\n"
          ]
        }
      ],
      "source": [
        "decoded_text = tokenizer.decode(encoded_text)\n",
        "print(\"Decoded tokens back into text: \", decoded_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0K1ifvKw7-qE"
      },
      "source": [
        "### Tokenize multiple texts at once"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "height": 64,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKUamOxv7-qE",
        "outputId": "11337a53-e607-448b-cd16-f9f0f3520cc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoded several texts:  [[12764, 13, 849, 403, 368, 32], [42, 1353, 1175], [4374]]\n"
          ]
        }
      ],
      "source": [
        "list_texts = [\"Hi, how are you?\", \"I'm good\", \"Yes\"]\n",
        "encoded_texts = tokenizer(list_texts)\n",
        "print(\"Encoded several texts: \", encoded_texts[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRQvicAz7-qE"
      },
      "source": [
        "### Padding and truncation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "height": 64,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOKls7i57-qE",
        "outputId": "3c8cbe9e-2b08-4a83-9e99-4e81e63831a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using padding:  [[12764, 13, 849, 403, 368, 32], [42, 1353, 1175, 0, 0, 0], [4374, 0, 0, 0, 0, 0]]\n"
          ]
        }
      ],
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "encoded_texts_longest = tokenizer(list_texts, padding=True)\n",
        "print(\"Using padding: \", encoded_texts_longest[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "height": 47,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zakMhvr7-qE",
        "outputId": "1e7045fc-9a33-46e7-d68d-8e538bea06f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using truncation:  [[12764, 13, 849], [42, 1353, 1175], [4374]]\n"
          ]
        }
      ],
      "source": [
        "encoded_texts_truncation = tokenizer(list_texts, max_length=3, truncation=True)\n",
        "print(\"Using truncation: \", encoded_texts_truncation[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "height": 64,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Tw-VNW37-qE",
        "outputId": "6125f932-a076-4a88-c80c-afa19598b82f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using left-side truncation:  [[403, 368, 32], [42, 1353, 1175], [4374]]\n"
          ]
        }
      ],
      "source": [
        "tokenizer.truncation_side = \"left\"\n",
        "encoded_texts_truncation_left = tokenizer(list_texts, max_length=3, truncation=True)\n",
        "print(\"Using left-side truncation: \", encoded_texts_truncation_left[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "height": 47,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QcszQNu7-qF",
        "outputId": "021a9cdc-7559-4c6b-c0e3-e07c75ac963a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using both padding and truncation:  [[403, 368, 32], [42, 1353, 1175], [4374, 0, 0]]\n"
          ]
        }
      ],
      "source": [
        "encoded_texts_both = tokenizer(list_texts, max_length=3, truncation=True, padding=True)\n",
        "print(\"Using both padding and truncation: \", encoded_texts_both[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzA2YR-J7-qF"
      },
      "source": [
        "### Prepare instruction dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "height": 540,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "collapsed": true,
        "id": "PUO7C31Y7-qF",
        "outputId": "e2fdef0c-e3f0-42a3-8128-4eaab0e68cac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1153976129.py:4: FutureWarning: Passing literal json to 'read_json' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
            "  instruction_dataset_df = pd.read_json(filename, lines=True)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Expected object or value",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1153976129.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"lamini_docs.jsonl\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0minstruction_dataset_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstruction_dataset_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread_json\u001b[0;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, precise_float, date_unit, encoding, encoding_errors, lines, chunksize, compression, nrows, storage_options, dtype_backend, engine)\u001b[0m\n\u001b[1;32m    813\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1021\u001b[0m                         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m                         \u001b[0mdata_lines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m                         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_combine_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m                     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_object_parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_get_object_parser\u001b[0;34m(self, json)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"frame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFrameParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"series\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1185\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1187\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/json/_json.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m             self.obj = DataFrame(\n\u001b[0;32m-> 1403\u001b[0;31m                 \u001b[0mujson_loads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecise_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1404\u001b[0m             )\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0morient\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"split\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected object or value"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "filename = \"lamini_docs.jsonl\"\n",
        "instruction_dataset_df = pd.read_json(filename, lines=True)\n",
        "examples = instruction_dataset_df.to_dict()\n",
        "print(examples)\n",
        "\n",
        "if \"question\" in examples and \"answer\" in examples:\n",
        "  text = examples[\"question\"][0] + examples[\"answer\"][0]\n",
        "elif \"instruction\" in examples and \"response\" in examples:\n",
        "  text = examples[\"instruction\"][0] + examples[\"response\"][0]\n",
        "elif \"input\" in examples and \"output\" in examples:\n",
        "  text = examples[\"input\"][0] + examples[\"output\"][0]\n",
        "else:\n",
        "  text = examples[\"text\"][0]\n",
        "\n",
        "prompt_template = \"\"\"### Question:\n",
        "{question}\n",
        "\n",
        "### Answer:\"\"\"\n",
        "\n",
        "num_examples = len(examples[\"question\"])\n",
        "finetuning_dataset = []\n",
        "for i in range(num_examples):\n",
        "  question = examples[\"question\"][i]\n",
        "  answer = examples[\"answer\"][i]\n",
        "  text_with_prompt_template = prompt_template.format(question=question)\n",
        "  finetuning_dataset.append({\"question\": text_with_prompt_template, \"answer\": answer})\n",
        "\n",
        "from pprint import pprint\n",
        "print(\"One datapoint in the finetuning dataset:\")\n",
        "pprint(finetuning_dataset[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvjrhC1J7-qF"
      },
      "source": [
        "### Tokenize a single example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 132,
        "id": "UHUwKbxs7-qF"
      },
      "outputs": [],
      "source": [
        "text = finetuning_dataset[0][\"question\"] + finetuning_dataset[0][\"answer\"]\n",
        "tokenized_inputs = tokenizer(\n",
        "    text,\n",
        "    return_tensors=\"np\",\n",
        "    padding=True\n",
        ")\n",
        "print(tokenized_inputs[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 132,
        "id": "dBL6qq_A7-qF"
      },
      "outputs": [],
      "source": [
        "max_length = 2048\n",
        "\n",
        "# it will assign 2048 if min() returned value <=2048, if min() returned >2048, we will set the max_length to 2048\n",
        "max_length = min(\n",
        "    tokenized_inputs[\"input_ids\"].shape[1],\n",
        "    max_length,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 115,
        "id": "XEVMBuLy7-qF"
      },
      "outputs": [],
      "source": [
        "tokenized_inputs = tokenizer(\n",
        "    text,\n",
        "    return_tensors=\"np\",\n",
        "    truncation=True,\n",
        "    max_length=max_length\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "LwD1jwrn7-qG"
      },
      "outputs": [],
      "source": [
        "tokenized_inputs[\"input_ids\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qpICSvp7-qG"
      },
      "source": [
        "### Tokenize the instruction dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 489,
        "id": "_HRepcAi7-qG"
      },
      "outputs": [],
      "source": [
        "def tokenize_function(examples):\n",
        "    if \"question\" in examples and \"answer\" in examples:\n",
        "        text = [q + a for q, a in zip(examples[\"question\"], examples[\"answer\"])]\n",
        "    elif \"input\" in examples and \"output\" in examples:\n",
        "        text = [i + o for i, o in zip(examples[\"input\"], examples[\"output\"])]\n",
        "    else:\n",
        "        text = examples[\"text\"]\n",
        "\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    tokenized_inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"np\",\n",
        "        padding=True,\n",
        "    )\n",
        "\n",
        "    max_length = min(\n",
        "        tokenized_inputs[\"input_ids\"].shape[1],\n",
        "        2048\n",
        "    )\n",
        "    tokenizer.truncation_side = \"left\"\n",
        "    tokenized_inputs = tokenizer(\n",
        "        text,\n",
        "        return_tensors=\"np\",\n",
        "        truncation=True,\n",
        "        max_length=max_length\n",
        "    )\n",
        "\n",
        "    return tokenized_inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 183,
        "id": "QOZOpyrN7-qG"
      },
      "outputs": [],
      "source": [
        "finetuning_dataset_loaded = datasets.load_dataset(\"json\", data_files=filename, split=\"train\")\n",
        "\n",
        "tokenized_dataset = finetuning_dataset_loaded.map(\n",
        "    tokenize_function,\n",
        "    batched=True,\n",
        "    batch_size=10,\n",
        "    drop_last_batch=True\n",
        ")\n",
        "\n",
        "print(tokenized_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 30,
        "id": "MhSjwxY27-qG"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset = tokenized_dataset.add_column(\"labels\", tokenized_dataset[\"input_ids\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIIDx5OC7-qG"
      },
      "source": [
        "### Prepare test/train splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 47,
        "id": "WvTuiDQ77-qG"
      },
      "outputs": [],
      "source": [
        "split_dataset = tokenized_dataset.train_test_split(test_size=0.1, shuffle=True, seed=123)\n",
        "print(split_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90-S2Ptv7-qG"
      },
      "source": [
        "### Some datasets for you to try"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "height": 64,
        "id": "JLabh-2H7-qH"
      },
      "outputs": [],
      "source": [
        "taylor_swift_dataset = \"lamini/taylor_swift\"\n",
        "bts_dataset = \"lamini/bts\"\n",
        "open_llms = \"lamini/open_llms\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "height": 47,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214,
          "referenced_widgets": [
            "3edac8c528ed400e8f9fedd8605d529b",
            "249eaa267fac4787ace2318c59103182",
            "e7a6a5cc666f4eaf97b65b259e17b6a4",
            "2b16ab33143047eca7233cc882822a90",
            "f1130d33111649cea41c79e31611325e",
            "f4d4cc9ed666479689563b736183ffb7",
            "b0f1587b07764b11b831d8c15042c198",
            "7a6c75405da64cbab8c11de49592f74f",
            "31b540d178a348e799660473dccf8bf8",
            "33c3293fa2ef419fb38f4fa84ead9eec",
            "f99cca6a9eed425fb72de73ace1a428a",
            "a0ff23df324141e4bc8fadc72c66bc63",
            "2bbb5db531ac40e684e27caa9652392e",
            "5ad1f857f15f49409892166ffdb6b6b9",
            "b38aa80303fc431fa452bbfbc856e38a",
            "5e4c61862f644ff190161eef8f7f6608",
            "f4239a2540b24bbfa26bd8ca1538f6af",
            "28aae787577a477eba751a1ddd3a1441",
            "d3595fbe6c634ed1aa2cb3b59c4f8310",
            "bea1176264de44a881ff8fda0899638d",
            "efdb825e4a63430f85daa624e567ee67",
            "258ff622ac364e01894d44219aed378c",
            "ce084c90f4164cd7842aea1784e749bd",
            "a7cb9d6623ff492d9e3daa2dc6df5367",
            "2713a019c9a641b7aecdbe23a169a912",
            "ba55e76df7de4803bbe6284932a789de",
            "fa2b848ab58a4e56a5865bf2aedecfbd",
            "27cab5c4faa74d518f4223e8cc1ac09f",
            "21b5052690de4dbabdd912b8e6d48c44",
            "1e2fdcd10c8d4bb9bcc4db7b72d1eaee",
            "710f5a48bcb449619f0c9640b745139a",
            "941cff6d9ad649e1b4e6c7f22f7627a6",
            "0d61d60c5b1b4e908dd5f13f2f2c9e58",
            "d406dd392dba4b56b61820b6941d3faa",
            "19cea0f4a459456f907a04a64ffc042b",
            "c9ecd20495834a49b6f8234b0ce31181",
            "5b2881e6f44f422d95eb69a5a0fbca9f",
            "e9b8dbf59952405d8d58078b5dc3976e",
            "b9aba786ec114c7e951325f1d95c9d21",
            "5f60309d2ba34e8b92749da57eb4285b",
            "3dd7ded156de4134aa13a8d11d0ee1d1",
            "d79f8685fda840918276805a54df8ac3",
            "aec219cae99f45b1afb397bfb381a016",
            "9b132597323d46eeb01bdef5a7a4d034",
            "7f648cf66726441fbb57c700a4a7ad91",
            "237cb77f594b4358af3f4ce835067bb6",
            "1a595dcef9044416a7be7f047d83337c",
            "66c2bd64f0d047c0ae3515b1fd06f385",
            "66cbe9f678e94da2b525509bb140ed4f",
            "55e84a5a96b64bb4a79c14157cb3632e",
            "07ee0ef2c92445f58335d5d2d7504971",
            "3ebd03c8f15c4666a25cdd15842fc596",
            "c837364a5f99412ca0cf773fc08b11d1",
            "3457a41fdf694d179a37f20bfd1b439b",
            "2e4c89b0af96419baa2240d92b15a33f"
          ]
        },
        "id": "vT2T-GI77-qH",
        "outputId": "18abb12a-f5d3-4e27-8021-1054f6a3a0d2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/573 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3edac8c528ed400e8f9fedd8605d529b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/train-00000-of-00001-54dd04266a81db(\u00e2\u20ac\u00a6):   0%|          | 0.00/257k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a0ff23df324141e4bc8fadc72c66bc63"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "data/test-00000-of-00001-185d72ed4b72e46(\u00e2\u20ac\u00a6):   0%|          | 0.00/46.3k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ce084c90f4164cd7842aea1784e749bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/783 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d406dd392dba4b56b61820b6941d3faa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/87 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f648cf66726441fbb57c700a4a7ad91"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'question': \"What is the controversy surrounding Taylor Swift's music and how has it impacted her career?\", 'answer': 'Taylor Swift has been involved in several controversies throughout her career, including her feud with Kanye West and Kim Kardashian, her lawsuit against a radio DJ who allegedly groped her, and her recent feud with Scooter Braun. These controversies have impacted her career in several ways. First, they have made her a more polarizing figure in the music industry, with some fans supporting her and others criticizing her. Second, they have led to a decrease in her popularity among some listeners, particularly those who do not agree with her political views or her actions in the feuds. Finally, they have led to a decrease of her music being played on some radio stations, which has impacted her ability to reach new audiences', 'input_ids': [1276, 310, 253, 16305, 8704, 11276, 24619, 434, 3440, 285, 849, 556, 352, 27857, 617, 5249, 32, 37979, 24619, 556, 644, 3206, 275, 2067, 9474, 447, 4768, 617, 5249, 13, 1690, 617, 40157, 342, 611, 1279, 70, 4255, 285, 10766, 611, 472, 1225, 757, 13, 617, 15091, 1411, 247, 5553, 22533, 665, 14163, 305, 1658, 264, 617, 13, 285, 617, 3332, 40157, 342, 1810, 37449, 47907, 15, 2053, 9474, 447, 452, 27857, 617, 5249, 275, 2067, 4088, 15, 3973, 13, 597, 452, 1160, 617, 247, 625, 6994, 3006, 4677, 275, 253, 3440, 4491, 13, 342, 690, 7458, 8109, 617, 285, 2571, 7291, 3006, 617, 15, 6347, 13, 597, 452, 3977, 281, 247, 6379, 275, 617, 18395, 2190, 690, 30418, 13, 3782, 1110, 665, 513, 417, 5194, 342, 617, 3569, 6849, 390, 617, 5231, 275, 253, 704, 36626, 15, 6610, 13, 597, 452, 3977, 281, 247, 6379, 273, 617, 3440, 1146, 4546, 327, 690, 5553, 10988, 13, 534, 556, 27857, 617, 3745, 281, 3986, 747, 23886], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [1276, 310, 253, 16305, 8704, 11276, 24619, 434, 3440, 285, 849, 556, 352, 27857, 617, 5249, 32, 37979, 24619, 556, 644, 3206, 275, 2067, 9474, 447, 4768, 617, 5249, 13, 1690, 617, 40157, 342, 611, 1279, 70, 4255, 285, 10766, 611, 472, 1225, 757, 13, 617, 15091, 1411, 247, 5553, 22533, 665, 14163, 305, 1658, 264, 617, 13, 285, 617, 3332, 40157, 342, 1810, 37449, 47907, 15, 2053, 9474, 447, 452, 27857, 617, 5249, 275, 2067, 4088, 15, 3973, 13, 597, 452, 1160, 617, 247, 625, 6994, 3006, 4677, 275, 253, 3440, 4491, 13, 342, 690, 7458, 8109, 617, 285, 2571, 7291, 3006, 617, 15, 6347, 13, 597, 452, 3977, 281, 247, 6379, 275, 617, 18395, 2190, 690, 30418, 13, 3782, 1110, 665, 513, 417, 5194, 342, 617, 3569, 6849, 390, 617, 5231, 275, 253, 704, 36626, 15, 6610, 13, 597, 452, 3977, 281, 247, 6379, 273, 617, 3440, 1146, 4546, 327, 690, 5553, 10988, 13, 534, 556, 27857, 617, 3745, 281, 3986, 747, 23886]}\n"
          ]
        }
      ],
      "source": [
        "dataset_swiftie = datasets.load_dataset(taylor_swift_dataset)\n",
        "print(dataset_swiftie[\"train\"][0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"lamini/taylor_swift\"\n",
        "examples = dataset_swiftie\n",
        "print(examples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZ4vIO659fpN",
        "outputId": "ea8683ff-5917-45da-b9b1-1b4db71dbd5f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 783\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['question', 'answer', 'input_ids', 'attention_mask', 'labels'],\n",
            "        num_rows: 87\n",
            "    })\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "height": 591,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zx2m9fQh7-qH",
        "outputId": "f130dcbe-6d60-4022-cd51-43b6c0b31e51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One datapoint in the finetuning dataset:\n",
            "{'answer': 'Taylor Swift has been involved in several controversies throughout '\n",
            "           'her career, including her feud with Kanye West and Kim Kardashian, '\n",
            "           'her lawsuit against a radio DJ who allegedly groped her, and her '\n",
            "           'recent feud with Scooter Braun. These controversies have impacted '\n",
            "           'her career in several ways. First, they have made her a more '\n",
            "           'polarizing figure in the music industry, with some fans supporting '\n",
            "           'her and others criticizing her. Second, they have led to a '\n",
            "           'decrease in her popularity among some listeners, particularly '\n",
            "           'those who do not agree with her political views or her actions in '\n",
            "           'the feuds. Finally, they have led to a decrease of her music being '\n",
            "           'played on some radio stations, which has impacted her ability to '\n",
            "           'reach new audiences',\n",
            " 'question': '### Question:\\n'\n",
            "             \"What is the controversy surrounding Taylor Swift's music and how \"\n",
            "             'has it impacted her career?\\n'\n",
            "             '\\n'\n",
            "             '### Answer:'}\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "filename = \"lamini/taylor_swift\"\n",
        "examples = dataset_swiftie[\"train\"]\n",
        "\n",
        "if \"question\" in examples.column_names and \"answer\" in examples.column_names:\n",
        "  text = examples[\"question\"][0] + examples[\"answer\"][0]\n",
        "elif \"instruction\" in examples.column_names and \"response\" in examples.column_names:\n",
        "  text = examples[\"instruction\"][0] + examples[\"response\"][0]\n",
        "elif \"input\" in examples.column_names and \"output\" in examples.column_names:\n",
        "  text = examples[\"input\"][0] + examples[\"output\"][0]\n",
        "\n",
        "prompt_template = \"\"\"### Question:\n",
        "{question}\n",
        "\n",
        "### Answer:\"\"\"\n",
        "\n",
        "num_examples = len(examples[\"question\"])\n",
        "finetuning_dataset = []\n",
        "for i in range(num_examples):\n",
        "  question = examples[\"question\"][i]\n",
        "  answer = examples[\"answer\"][i]\n",
        "  text_with_prompt_template = prompt_template.format(question=question)\n",
        "  finetuning_dataset.append({\"question\": text_with_prompt_template, \"answer\": answer})\n",
        "\n",
        "from pprint import pprint\n",
        "print(\"One datapoint in the finetuning dataset:\")\n",
        "pprint(finetuning_dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "height": 81,
        "id": "N5jQayVfSOP0"
      },
      "outputs": [],
      "source": [
        "# This is how to push your own dataset to your Huggingface hub\n",
        "# !pip install huggingface_hub\n",
        "# !huggingface-cli login\n",
        "# split_dataset.push_to_hub(dataset_path_hf)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}